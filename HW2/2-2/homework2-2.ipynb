{"cells":[{"cell_type":"markdown","metadata":{"id":"rvC4fdcO9rcp"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eq_vrG3-9dBN"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3141,"status":"ok","timestamp":1686217703221,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"dp9xwbbK9xgn","outputId":"ddb78c26-1006-460a-9676-815d626b53ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# read files from google drive\n","import os\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/NTU_MLDS_Spring2018/HW2'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","# print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# import modules from google drive\n","import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)"]},{"cell_type":"markdown","metadata":{"id":"0oGxTQzs949M"},"source":["# Download dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A88NxiCL9xeA"},"outputs":[],"source":["# update gdown, if it failed to download large files\n","# !pip install --upgrade --no-cache-dir gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6593,"status":"ok","timestamp":1686194930903,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"D4xZic5X9xbC","outputId":"1021d9fd-ce73-4855-b792-c9a9327bda49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1JTwZ4RyEApT60v_CLHp7xAAfrirQQDEd\n","To: /content/clr_conversation.txt\n","100% 88.6M/88.6M [00:01<00:00, 84.6MB/s]\n"]}],"source":["# clr_conversation.txt\n","!gdown https://drive.google.com/uc?id=1JTwZ4RyEApT60v_CLHp7xAAfrirQQDEd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":865,"status":"ok","timestamp":1686194931764,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"bi-wUZpl9xYO","outputId":"bdb20f48-f49d-4c71-ea5c-b541ce15c0a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1I1oYmhtbYzVgDLVQJ1Uv9soGSiMyB5rD\n","To: /content/test_input.txt\n","\r  0% 0.00/314k [00:00<?, ?B/s]\r100% 314k/314k [00:00<00:00, 86.6MB/s]\n"]}],"source":["# testing data\n","!gdown https://drive.google.com/uc?id=1I1oYmhtbYzVgDLVQJ1Uv9soGSiMyB5rD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_fa5kEb9xUT"},"outputs":[],"source":["# baseline code / evaluation\n","# !gdown https://drive.google.com/uc?id=1pLREvo9ptzdg_NHgZESlj-vr1N60MpOF\n","# !tar -zxf evaluation.tar.gz  # don't show the progress"]},{"cell_type":"markdown","metadata":{"id":"qTWXyLI1-wbG"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1686217709299,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"L4oivlFwCbs4","outputId":"4991ef5d-2896-45f7-f5f2-341945a6099b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2\n"]}],"source":["%cd $GOOGLE_DRIVE_PATH/2-2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCozV7xG9xF-"},"outputs":[],"source":["convo_file = '/content/clr_conversation.txt'\n","test_file = '/content/test_input.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWjV9-oC9w4U","executionInfo":{"status":"ok","timestamp":1686217393334,"user_tz":-540,"elapsed":22461096,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"d9be8c9d-6cbd-43a8-c3c5-6e035af30dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(train_data='/content/clr_conversation.txt', num_epochs=200)\n","Building vocabulary...\n","Finished.\n","Vocabulary sizes: 10174\n","Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(10174, 1024, padding_idx=0)\n","    (gru): GRU(1024, 512, num_layers=2, batch_first=True, dropout=0.5)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(10174, 1024, padding_idx=0)\n","    (attn): Attention(\n","      (w_en): Linear(in_features=512, out_features=512, bias=True)\n","      (w_de): Linear(in_features=512, out_features=512, bias=True)\n","      (v): Linear(in_features=512, out_features=1, bias=False)\n","    )\n","    (gru): GRU(1536, 512, num_layers=2, batch_first=True, dropout=0.5)\n","    (fc_out): Linear(in_features=2048, out_features=10174, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n","Epoch: 01 | Time: 1m 51s\n","\tTrain Loss: 5.434 | Train PPL: 229.173\n","\t Val. Loss: 5.542 |  Val. PPL: 255.210\n","Epoch: 02 | Time: 1m 50s\n","\tTrain Loss: 5.184 | Train PPL: 178.371\n","\t Val. Loss: 5.496 |  Val. PPL: 243.738\n","Epoch: 03 | Time: 1m 50s\n","\tTrain Loss: 5.085 | Train PPL: 161.617\n","\t Val. Loss: 5.505 |  Val. PPL: 245.934\n","Epoch: 04 | Time: 1m 51s\n","\tTrain Loss: 5.025 | Train PPL: 152.128\n","\t Val. Loss: 5.447 |  Val. PPL: 231.956\n","Epoch: 05 | Time: 1m 50s\n","\tTrain Loss: 4.968 | Train PPL: 143.766\n","\t Val. Loss: 5.438 |  Val. PPL: 229.909\n","Epoch: 06 | Time: 1m 50s\n","\tTrain Loss: 4.934 | Train PPL: 138.899\n","\t Val. Loss: 5.452 |  Val. PPL: 233.219\n","Epoch: 07 | Time: 1m 51s\n","\tTrain Loss: 4.898 | Train PPL: 133.968\n","\t Val. Loss: 5.418 |  Val. PPL: 225.460\n","Epoch: 08 | Time: 1m 51s\n","\tTrain Loss: 4.867 | Train PPL: 129.990\n","\t Val. Loss: 5.429 |  Val. PPL: 227.975\n","Epoch: 09 | Time: 1m 51s\n","\tTrain Loss: 4.847 | Train PPL: 127.358\n","\t Val. Loss: 5.442 |  Val. PPL: 230.842\n","Epoch: 10 | Time: 1m 51s\n","\tTrain Loss: 4.795 | Train PPL: 120.902\n","\t Val. Loss: 5.401 |  Val. PPL: 221.547\n","Epoch: 11 | Time: 1m 51s\n","\tTrain Loss: 4.804 | Train PPL: 122.026\n","\t Val. Loss: 5.404 |  Val. PPL: 222.290\n","Epoch: 12 | Time: 1m 51s\n","\tTrain Loss: 4.763 | Train PPL: 117.047\n","\t Val. Loss: 5.410 |  Val. PPL: 223.679\n","Epoch: 13 | Time: 1m 52s\n","\tTrain Loss: 4.737 | Train PPL: 114.098\n","\t Val. Loss: 5.379 |  Val. PPL: 216.884\n","Epoch: 14 | Time: 1m 50s\n","\tTrain Loss: 4.733 | Train PPL: 113.587\n","\t Val. Loss: 5.393 |  Val. PPL: 219.770\n","Epoch: 15 | Time: 1m 51s\n","\tTrain Loss: 4.725 | Train PPL: 112.767\n","\t Val. Loss: 5.402 |  Val. PPL: 221.854\n","Epoch: 16 | Time: 1m 51s\n","\tTrain Loss: 4.716 | Train PPL: 111.687\n","\t Val. Loss: 5.379 |  Val. PPL: 216.752\n","Epoch: 17 | Time: 1m 50s\n","\tTrain Loss: 4.691 | Train PPL: 108.930\n","\t Val. Loss: 5.413 |  Val. PPL: 224.385\n","Epoch: 18 | Time: 1m 51s\n","\tTrain Loss: 4.673 | Train PPL: 107.056\n","\t Val. Loss: 5.421 |  Val. PPL: 226.058\n","Epoch: 19 | Time: 1m 51s\n","\tTrain Loss: 4.662 | Train PPL: 105.876\n","\t Val. Loss: 5.355 |  Val. PPL: 211.597\n","Epoch: 20 | Time: 1m 51s\n","\tTrain Loss: 4.648 | Train PPL: 104.408\n","\t Val. Loss: 5.409 |  Val. PPL: 223.466\n","Epoch: 21 | Time: 1m 51s\n","\tTrain Loss: 4.646 | Train PPL: 104.176\n","\t Val. Loss: 5.373 |  Val. PPL: 215.540\n","Epoch: 22 | Time: 1m 51s\n","\tTrain Loss: 4.622 | Train PPL: 101.652\n","\t Val. Loss: 5.400 |  Val. PPL: 221.441\n","Epoch: 23 | Time: 1m 51s\n","\tTrain Loss: 4.609 | Train PPL: 100.431\n","\t Val. Loss: 5.403 |  Val. PPL: 222.043\n","Epoch: 24 | Time: 1m 51s\n","\tTrain Loss: 4.611 | Train PPL: 100.624\n","\t Val. Loss: 5.350 |  Val. PPL: 210.532\n","Epoch: 25 | Time: 1m 52s\n","\tTrain Loss: 4.606 | Train PPL: 100.125\n","\t Val. Loss: 5.375 |  Val. PPL: 216.014\n","Epoch: 26 | Time: 1m 51s\n","\tTrain Loss: 4.591 | Train PPL:  98.608\n","\t Val. Loss: 5.350 |  Val. PPL: 210.621\n","Epoch: 27 | Time: 1m 51s\n","\tTrain Loss: 4.583 | Train PPL:  97.832\n","\t Val. Loss: 5.378 |  Val. PPL: 216.678\n","Epoch: 28 | Time: 1m 51s\n","\tTrain Loss: 4.577 | Train PPL:  97.179\n","\t Val. Loss: 5.429 |  Val. PPL: 227.903\n","Epoch: 29 | Time: 1m 51s\n","\tTrain Loss: 4.573 | Train PPL:  96.841\n","\t Val. Loss: 5.390 |  Val. PPL: 219.171\n","Epoch: 30 | Time: 1m 51s\n","\tTrain Loss: 4.552 | Train PPL:  94.805\n","\t Val. Loss: 5.371 |  Val. PPL: 214.980\n","Epoch: 31 | Time: 1m 51s\n","\tTrain Loss: 4.548 | Train PPL:  94.487\n","\t Val. Loss: 5.413 |  Val. PPL: 224.338\n","Epoch: 32 | Time: 1m 51s\n","\tTrain Loss: 4.539 | Train PPL:  93.568\n","\t Val. Loss: 5.341 |  Val. PPL: 208.790\n","Epoch: 33 | Time: 1m 50s\n","\tTrain Loss: 4.536 | Train PPL:  93.291\n","\t Val. Loss: 5.369 |  Val. PPL: 214.583\n","Epoch: 34 | Time: 1m 51s\n","\tTrain Loss: 4.524 | Train PPL:  92.218\n","\t Val. Loss: 5.397 |  Val. PPL: 220.735\n","Epoch: 35 | Time: 1m 51s\n","\tTrain Loss: 4.513 | Train PPL:  91.221\n","\t Val. Loss: 5.417 |  Val. PPL: 225.146\n","Epoch: 36 | Time: 1m 50s\n","\tTrain Loss: 4.510 | Train PPL:  90.954\n","\t Val. Loss: 5.323 |  Val. PPL: 204.953\n","Epoch: 37 | Time: 1m 51s\n","\tTrain Loss: 4.517 | Train PPL:  91.596\n","\t Val. Loss: 5.391 |  Val. PPL: 219.396\n","Epoch: 38 | Time: 1m 52s\n","\tTrain Loss: 4.505 | Train PPL:  90.501\n","\t Val. Loss: 5.322 |  Val. PPL: 204.764\n","Epoch: 39 | Time: 1m 50s\n","\tTrain Loss: 4.501 | Train PPL:  90.095\n","\t Val. Loss: 5.367 |  Val. PPL: 214.162\n","Epoch: 40 | Time: 1m 50s\n","\tTrain Loss: 4.493 | Train PPL:  89.355\n","\t Val. Loss: 5.372 |  Val. PPL: 215.194\n","Epoch: 41 | Time: 1m 50s\n","\tTrain Loss: 4.484 | Train PPL:  88.558\n","\t Val. Loss: 5.320 |  Val. PPL: 204.310\n","Epoch: 42 | Time: 1m 51s\n","\tTrain Loss: 4.466 | Train PPL:  86.983\n","\t Val. Loss: 5.372 |  Val. PPL: 215.339\n","Epoch: 43 | Time: 1m 50s\n","\tTrain Loss: 4.473 | Train PPL:  87.648\n","\t Val. Loss: 5.357 |  Val. PPL: 212.018\n","Epoch: 44 | Time: 1m 51s\n","\tTrain Loss: 4.478 | Train PPL:  88.090\n","\t Val. Loss: 5.367 |  Val. PPL: 214.193\n","Epoch: 45 | Time: 1m 50s\n","\tTrain Loss: 4.473 | Train PPL:  87.647\n","\t Val. Loss: 5.380 |  Val. PPL: 216.972\n","Epoch: 46 | Time: 1m 51s\n","\tTrain Loss: 4.447 | Train PPL:  85.352\n","\t Val. Loss: 5.333 |  Val. PPL: 207.045\n","Epoch: 47 | Time: 1m 51s\n","\tTrain Loss: 4.466 | Train PPL:  86.974\n","\t Val. Loss: 5.353 |  Val. PPL: 211.251\n","Epoch: 48 | Time: 1m 51s\n","\tTrain Loss: 4.466 | Train PPL:  86.993\n","\t Val. Loss: 5.315 |  Val. PPL: 203.406\n","Epoch: 49 | Time: 1m 50s\n","\tTrain Loss: 4.446 | Train PPL:  85.254\n","\t Val. Loss: 5.340 |  Val. PPL: 208.595\n","Epoch: 50 | Time: 1m 49s\n","\tTrain Loss: 4.437 | Train PPL:  84.484\n","\t Val. Loss: 5.339 |  Val. PPL: 208.253\n","Epoch: 51 | Time: 1m 51s\n","\tTrain Loss: 4.438 | Train PPL:  84.578\n","\t Val. Loss: 5.337 |  Val. PPL: 207.884\n","Epoch: 52 | Time: 1m 51s\n","\tTrain Loss: 4.434 | Train PPL:  84.285\n","\t Val. Loss: 5.327 |  Val. PPL: 205.855\n","Epoch: 53 | Time: 1m 51s\n","\tTrain Loss: 4.426 | Train PPL:  83.577\n","\t Val. Loss: 5.309 |  Val. PPL: 202.153\n","Epoch: 54 | Time: 1m 50s\n","\tTrain Loss: 4.433 | Train PPL:  84.196\n","\t Val. Loss: 5.340 |  Val. PPL: 208.509\n","Epoch: 55 | Time: 1m 50s\n","\tTrain Loss: 4.419 | Train PPL:  83.051\n","\t Val. Loss: 5.363 |  Val. PPL: 213.389\n","Epoch: 56 | Time: 1m 51s\n","\tTrain Loss: 4.430 | Train PPL:  83.938\n","\t Val. Loss: 5.400 |  Val. PPL: 221.303\n","Epoch: 57 | Time: 1m 51s\n","\tTrain Loss: 4.412 | Train PPL:  82.430\n","\t Val. Loss: 5.391 |  Val. PPL: 219.527\n","Epoch: 58 | Time: 1m 51s\n","\tTrain Loss: 4.423 | Train PPL:  83.366\n","\t Val. Loss: 5.353 |  Val. PPL: 211.230\n","Epoch: 59 | Time: 1m 51s\n","\tTrain Loss: 4.408 | Train PPL:  82.076\n","\t Val. Loss: 5.338 |  Val. PPL: 208.192\n","Epoch: 60 | Time: 1m 51s\n","\tTrain Loss: 4.392 | Train PPL:  80.813\n","\t Val. Loss: 5.306 |  Val. PPL: 201.477\n","Epoch: 61 | Time: 1m 51s\n","\tTrain Loss: 4.400 | Train PPL:  81.476\n","\t Val. Loss: 5.309 |  Val. PPL: 202.216\n","Epoch: 62 | Time: 1m 51s\n","\tTrain Loss: 4.400 | Train PPL:  81.429\n","\t Val. Loss: 5.386 |  Val. PPL: 218.284\n","Epoch: 63 | Time: 1m 51s\n","\tTrain Loss: 4.380 | Train PPL:  79.874\n","\t Val. Loss: 5.366 |  Val. PPL: 213.956\n","Epoch: 64 | Time: 1m 51s\n","\tTrain Loss: 4.376 | Train PPL:  79.495\n","\t Val. Loss: 5.359 |  Val. PPL: 212.601\n","Epoch: 65 | Time: 1m 51s\n","\tTrain Loss: 4.392 | Train PPL:  80.815\n","\t Val. Loss: 5.356 |  Val. PPL: 211.905\n","Epoch: 66 | Time: 1m 51s\n","\tTrain Loss: 4.374 | Train PPL:  79.374\n","\t Val. Loss: 5.387 |  Val. PPL: 218.456\n","Epoch: 67 | Time: 1m 51s\n","\tTrain Loss: 4.379 | Train PPL:  79.737\n","\t Val. Loss: 5.388 |  Val. PPL: 218.871\n","Epoch: 68 | Time: 1m 52s\n","\tTrain Loss: 4.397 | Train PPL:  81.211\n","\t Val. Loss: 5.348 |  Val. PPL: 210.103\n","Epoch: 69 | Time: 1m 52s\n","\tTrain Loss: 4.367 | Train PPL:  78.794\n","\t Val. Loss: 5.371 |  Val. PPL: 215.106\n","Epoch: 70 | Time: 1m 51s\n","\tTrain Loss: 4.374 | Train PPL:  79.337\n","\t Val. Loss: 5.391 |  Val. PPL: 219.392\n","Epoch: 71 | Time: 1m 51s\n","\tTrain Loss: 4.371 | Train PPL:  79.091\n","\t Val. Loss: 5.359 |  Val. PPL: 212.499\n","Epoch: 72 | Time: 1m 51s\n","\tTrain Loss: 4.354 | Train PPL:  77.753\n","\t Val. Loss: 5.391 |  Val. PPL: 219.414\n","Epoch: 73 | Time: 1m 51s\n","\tTrain Loss: 4.336 | Train PPL:  76.386\n","\t Val. Loss: 5.389 |  Val. PPL: 219.026\n","Epoch: 74 | Time: 1m 51s\n","\tTrain Loss: 4.352 | Train PPL:  77.617\n","\t Val. Loss: 5.345 |  Val. PPL: 209.623\n","Epoch: 75 | Time: 1m 51s\n","\tTrain Loss: 4.366 | Train PPL:  78.695\n","\t Val. Loss: 5.359 |  Val. PPL: 212.443\n","Epoch: 76 | Time: 1m 51s\n","\tTrain Loss: 4.347 | Train PPL:  77.209\n","\t Val. Loss: 5.385 |  Val. PPL: 218.136\n","Epoch: 77 | Time: 1m 51s\n","\tTrain Loss: 4.365 | Train PPL:  78.671\n","\t Val. Loss: 5.364 |  Val. PPL: 213.662\n","Epoch: 78 | Time: 1m 51s\n","\tTrain Loss: 4.324 | Train PPL:  75.479\n","\t Val. Loss: 5.325 |  Val. PPL: 205.333\n","Epoch: 79 | Time: 1m 52s\n","\tTrain Loss: 4.331 | Train PPL:  76.054\n","\t Val. Loss: 5.389 |  Val. PPL: 219.091\n","Epoch: 80 | Time: 1m 52s\n","\tTrain Loss: 4.324 | Train PPL:  75.501\n","\t Val. Loss: 5.351 |  Val. PPL: 210.796\n","Epoch: 81 | Time: 1m 52s\n","\tTrain Loss: 4.337 | Train PPL:  76.487\n","\t Val. Loss: 5.375 |  Val. PPL: 215.967\n","Epoch: 82 | Time: 1m 52s\n","\tTrain Loss: 4.328 | Train PPL:  75.804\n","\t Val. Loss: 5.393 |  Val. PPL: 219.849\n","Epoch: 83 | Time: 1m 51s\n","\tTrain Loss: 4.331 | Train PPL:  75.988\n","\t Val. Loss: 5.371 |  Val. PPL: 215.166\n","Epoch: 84 | Time: 1m 52s\n","\tTrain Loss: 4.325 | Train PPL:  75.544\n","\t Val. Loss: 5.350 |  Val. PPL: 210.600\n","Epoch: 85 | Time: 1m 51s\n","\tTrain Loss: 4.329 | Train PPL:  75.901\n","\t Val. Loss: 5.350 |  Val. PPL: 210.608\n","Epoch: 86 | Time: 1m 51s\n","\tTrain Loss: 4.315 | Train PPL:  74.844\n","\t Val. Loss: 5.383 |  Val. PPL: 217.752\n","Epoch: 87 | Time: 1m 53s\n","\tTrain Loss: 4.314 | Train PPL:  74.727\n","\t Val. Loss: 5.368 |  Val. PPL: 214.518\n","Epoch: 88 | Time: 1m 52s\n","\tTrain Loss: 4.315 | Train PPL:  74.780\n","\t Val. Loss: 5.368 |  Val. PPL: 214.356\n","Epoch: 89 | Time: 1m 51s\n","\tTrain Loss: 4.309 | Train PPL:  74.348\n","\t Val. Loss: 5.381 |  Val. PPL: 217.141\n","Epoch: 90 | Time: 1m 52s\n","\tTrain Loss: 4.295 | Train PPL:  73.328\n","\t Val. Loss: 5.386 |  Val. PPL: 218.424\n","Epoch: 91 | Time: 1m 52s\n","\tTrain Loss: 4.303 | Train PPL:  73.947\n","\t Val. Loss: 5.419 |  Val. PPL: 225.552\n","Epoch: 92 | Time: 1m 52s\n","\tTrain Loss: 4.302 | Train PPL:  73.841\n","\t Val. Loss: 5.363 |  Val. PPL: 213.425\n","Epoch: 93 | Time: 1m 52s\n","\tTrain Loss: 4.303 | Train PPL:  73.924\n","\t Val. Loss: 5.346 |  Val. PPL: 209.854\n","Epoch: 94 | Time: 1m 52s\n","\tTrain Loss: 4.301 | Train PPL:  73.740\n","\t Val. Loss: 5.386 |  Val. PPL: 218.224\n","Epoch: 95 | Time: 1m 52s\n","\tTrain Loss: 4.288 | Train PPL:  72.826\n","\t Val. Loss: 5.327 |  Val. PPL: 205.895\n","Epoch: 96 | Time: 1m 51s\n","\tTrain Loss: 4.287 | Train PPL:  72.731\n","\t Val. Loss: 5.368 |  Val. PPL: 214.527\n","Epoch: 97 | Time: 1m 51s\n","\tTrain Loss: 4.287 | Train PPL:  72.722\n","\t Val. Loss: 5.403 |  Val. PPL: 221.972\n","Epoch: 98 | Time: 1m 52s\n","\tTrain Loss: 4.292 | Train PPL:  73.093\n","\t Val. Loss: 5.347 |  Val. PPL: 210.054\n","Epoch: 99 | Time: 1m 53s\n","\tTrain Loss: 4.287 | Train PPL:  72.712\n","\t Val. Loss: 5.371 |  Val. PPL: 215.077\n","Epoch: 100 | Time: 1m 52s\n","\tTrain Loss: 4.282 | Train PPL:  72.396\n","\t Val. Loss: 5.398 |  Val. PPL: 220.926\n","Epoch: 101 | Time: 1m 51s\n","\tTrain Loss: 4.270 | Train PPL:  71.548\n","\t Val. Loss: 5.389 |  Val. PPL: 219.070\n","Epoch: 102 | Time: 1m 52s\n","\tTrain Loss: 4.276 | Train PPL:  71.931\n","\t Val. Loss: 5.398 |  Val. PPL: 221.067\n","Epoch: 103 | Time: 1m 52s\n","\tTrain Loss: 4.291 | Train PPL:  73.027\n","\t Val. Loss: 5.335 |  Val. PPL: 207.548\n","Epoch: 104 | Time: 1m 52s\n","\tTrain Loss: 4.289 | Train PPL:  72.891\n","\t Val. Loss: 5.342 |  Val. PPL: 208.826\n","Epoch: 105 | Time: 1m 52s\n","\tTrain Loss: 4.279 | Train PPL:  72.176\n","\t Val. Loss: 5.388 |  Val. PPL: 218.867\n","Epoch: 106 | Time: 1m 51s\n","\tTrain Loss: 4.269 | Train PPL:  71.465\n","\t Val. Loss: 5.382 |  Val. PPL: 217.555\n","Epoch: 107 | Time: 1m 52s\n","\tTrain Loss: 4.269 | Train PPL:  71.475\n","\t Val. Loss: 5.387 |  Val. PPL: 218.568\n","Epoch: 108 | Time: 1m 51s\n","\tTrain Loss: 4.277 | Train PPL:  72.047\n","\t Val. Loss: 5.320 |  Val. PPL: 204.464\n","Epoch: 109 | Time: 1m 51s\n","\tTrain Loss: 4.265 | Train PPL:  71.191\n","\t Val. Loss: 5.396 |  Val. PPL: 220.564\n","Epoch: 110 | Time: 1m 52s\n","\tTrain Loss: 4.261 | Train PPL:  70.907\n","\t Val. Loss: 5.331 |  Val. PPL: 206.742\n","Epoch: 111 | Time: 1m 52s\n","\tTrain Loss: 4.252 | Train PPL:  70.232\n","\t Val. Loss: 5.379 |  Val. PPL: 216.823\n","Epoch: 112 | Time: 1m 53s\n","\tTrain Loss: 4.253 | Train PPL:  70.290\n","\t Val. Loss: 5.341 |  Val. PPL: 208.687\n","Epoch: 113 | Time: 1m 53s\n","\tTrain Loss: 4.253 | Train PPL:  70.331\n","\t Val. Loss: 5.352 |  Val. PPL: 211.017\n","Epoch: 114 | Time: 1m 52s\n","\tTrain Loss: 4.252 | Train PPL:  70.232\n","\t Val. Loss: 5.388 |  Val. PPL: 218.785\n","Epoch: 115 | Time: 1m 52s\n","\tTrain Loss: 4.235 | Train PPL:  69.075\n","\t Val. Loss: 5.396 |  Val. PPL: 220.513\n","Epoch: 116 | Time: 1m 51s\n","\tTrain Loss: 4.241 | Train PPL:  69.493\n","\t Val. Loss: 5.388 |  Val. PPL: 218.757\n","Epoch: 117 | Time: 1m 52s\n","\tTrain Loss: 4.234 | Train PPL:  68.974\n","\t Val. Loss: 5.417 |  Val. PPL: 225.277\n","Epoch: 118 | Time: 1m 53s\n","\tTrain Loss: 4.256 | Train PPL:  70.524\n","\t Val. Loss: 5.341 |  Val. PPL: 208.672\n","Epoch: 119 | Time: 1m 52s\n","\tTrain Loss: 4.227 | Train PPL:  68.521\n","\t Val. Loss: 5.350 |  Val. PPL: 210.591\n","Epoch: 120 | Time: 1m 52s\n","\tTrain Loss: 4.247 | Train PPL:  69.871\n","\t Val. Loss: 5.376 |  Val. PPL: 216.160\n","Epoch: 121 | Time: 1m 52s\n","\tTrain Loss: 4.248 | Train PPL:  69.943\n","\t Val. Loss: 5.362 |  Val. PPL: 213.221\n","Epoch: 122 | Time: 1m 52s\n","\tTrain Loss: 4.215 | Train PPL:  67.679\n","\t Val. Loss: 5.334 |  Val. PPL: 207.269\n","Epoch: 123 | Time: 1m 52s\n","\tTrain Loss: 4.239 | Train PPL:  69.367\n","\t Val. Loss: 5.364 |  Val. PPL: 213.575\n","Epoch: 124 | Time: 1m 52s\n","\tTrain Loss: 4.228 | Train PPL:  68.560\n","\t Val. Loss: 5.426 |  Val. PPL: 227.266\n","Epoch: 125 | Time: 1m 52s\n","\tTrain Loss: 4.236 | Train PPL:  69.132\n","\t Val. Loss: 5.334 |  Val. PPL: 207.251\n","Epoch: 126 | Time: 1m 51s\n","\tTrain Loss: 4.226 | Train PPL:  68.429\n","\t Val. Loss: 5.389 |  Val. PPL: 218.878\n","Epoch: 127 | Time: 1m 51s\n","\tTrain Loss: 4.231 | Train PPL:  68.788\n","\t Val. Loss: 5.361 |  Val. PPL: 212.904\n","Epoch: 128 | Time: 1m 51s\n","\tTrain Loss: 4.226 | Train PPL:  68.430\n","\t Val. Loss: 5.373 |  Val. PPL: 215.497\n","Epoch: 129 | Time: 1m 51s\n","\tTrain Loss: 4.212 | Train PPL:  67.513\n","\t Val. Loss: 5.378 |  Val. PPL: 216.639\n","Epoch: 130 | Time: 1m 52s\n","\tTrain Loss: 4.212 | Train PPL:  67.514\n","\t Val. Loss: 5.381 |  Val. PPL: 217.303\n","Epoch: 131 | Time: 1m 53s\n","\tTrain Loss: 4.223 | Train PPL:  68.255\n","\t Val. Loss: 5.393 |  Val. PPL: 219.772\n","Epoch: 132 | Time: 1m 54s\n","\tTrain Loss: 4.213 | Train PPL:  67.545\n","\t Val. Loss: 5.389 |  Val. PPL: 219.019\n","Epoch: 133 | Time: 1m 53s\n","\tTrain Loss: 4.212 | Train PPL:  67.513\n","\t Val. Loss: 5.380 |  Val. PPL: 217.117\n","Epoch: 134 | Time: 1m 53s\n","\tTrain Loss: 4.218 | Train PPL:  67.884\n","\t Val. Loss: 5.389 |  Val. PPL: 219.053\n","Epoch: 135 | Time: 1m 52s\n","\tTrain Loss: 4.196 | Train PPL:  66.388\n","\t Val. Loss: 5.351 |  Val. PPL: 210.748\n","Epoch: 136 | Time: 1m 52s\n","\tTrain Loss: 4.197 | Train PPL:  66.464\n","\t Val. Loss: 5.404 |  Val. PPL: 222.256\n","Epoch: 137 | Time: 1m 53s\n","\tTrain Loss: 4.196 | Train PPL:  66.420\n","\t Val. Loss: 5.341 |  Val. PPL: 208.738\n","Epoch: 138 | Time: 1m 52s\n","\tTrain Loss: 4.185 | Train PPL:  65.704\n","\t Val. Loss: 5.377 |  Val. PPL: 216.269\n","Epoch: 139 | Time: 1m 53s\n","\tTrain Loss: 4.203 | Train PPL:  66.869\n","\t Val. Loss: 5.388 |  Val. PPL: 218.865\n","Epoch: 140 | Time: 1m 52s\n","\tTrain Loss: 4.189 | Train PPL:  65.953\n","\t Val. Loss: 5.388 |  Val. PPL: 218.761\n","Epoch: 141 | Time: 1m 51s\n","\tTrain Loss: 4.183 | Train PPL:  65.592\n","\t Val. Loss: 5.383 |  Val. PPL: 217.633\n","Epoch: 142 | Time: 1m 51s\n","\tTrain Loss: 4.191 | Train PPL:  66.095\n","\t Val. Loss: 5.370 |  Val. PPL: 214.938\n","Epoch: 143 | Time: 1m 52s\n","\tTrain Loss: 4.186 | Train PPL:  65.729\n","\t Val. Loss: 5.402 |  Val. PPL: 221.872\n","Epoch: 144 | Time: 1m 52s\n","\tTrain Loss: 4.197 | Train PPL:  66.463\n","\t Val. Loss: 5.424 |  Val. PPL: 226.861\n","Epoch: 145 | Time: 1m 51s\n","\tTrain Loss: 4.175 | Train PPL:  65.051\n","\t Val. Loss: 5.367 |  Val. PPL: 214.284\n","Epoch: 146 | Time: 1m 53s\n","\tTrain Loss: 4.181 | Train PPL:  65.410\n","\t Val. Loss: 5.415 |  Val. PPL: 224.750\n","Epoch: 147 | Time: 1m 52s\n","\tTrain Loss: 4.172 | Train PPL:  64.832\n","\t Val. Loss: 5.378 |  Val. PPL: 216.656\n","Epoch: 148 | Time: 1m 52s\n","\tTrain Loss: 4.177 | Train PPL:  65.151\n","\t Val. Loss: 5.392 |  Val. PPL: 219.611\n","Epoch: 149 | Time: 1m 52s\n","\tTrain Loss: 4.169 | Train PPL:  64.632\n","\t Val. Loss: 5.364 |  Val. PPL: 213.619\n","Epoch: 150 | Time: 1m 52s\n","\tTrain Loss: 4.169 | Train PPL:  64.666\n","\t Val. Loss: 5.388 |  Val. PPL: 218.795\n","Epoch: 151 | Time: 1m 52s\n","\tTrain Loss: 4.180 | Train PPL:  65.379\n","\t Val. Loss: 5.390 |  Val. PPL: 219.135\n","Epoch: 152 | Time: 1m 52s\n","\tTrain Loss: 4.162 | Train PPL:  64.224\n","\t Val. Loss: 5.399 |  Val. PPL: 221.251\n","Epoch: 153 | Time: 1m 52s\n","\tTrain Loss: 4.176 | Train PPL:  65.133\n","\t Val. Loss: 5.391 |  Val. PPL: 219.334\n","Epoch: 154 | Time: 1m 52s\n","\tTrain Loss: 4.166 | Train PPL:  64.435\n","\t Val. Loss: 5.413 |  Val. PPL: 224.242\n","Epoch: 155 | Time: 1m 52s\n","\tTrain Loss: 4.180 | Train PPL:  65.342\n","\t Val. Loss: 5.390 |  Val. PPL: 219.262\n","Epoch: 156 | Time: 1m 52s\n","\tTrain Loss: 4.155 | Train PPL:  63.753\n","\t Val. Loss: 5.401 |  Val. PPL: 221.545\n","Epoch: 157 | Time: 1m 53s\n","\tTrain Loss: 4.181 | Train PPL:  65.454\n","\t Val. Loss: 5.356 |  Val. PPL: 211.827\n","Epoch: 158 | Time: 1m 52s\n","\tTrain Loss: 4.158 | Train PPL:  63.960\n","\t Val. Loss: 5.439 |  Val. PPL: 230.201\n","Epoch: 159 | Time: 1m 52s\n","\tTrain Loss: 4.155 | Train PPL:  63.726\n","\t Val. Loss: 5.430 |  Val. PPL: 228.246\n","Epoch: 160 | Time: 1m 53s\n","\tTrain Loss: 4.157 | Train PPL:  63.903\n","\t Val. Loss: 5.385 |  Val. PPL: 218.078\n","Epoch: 161 | Time: 1m 53s\n","\tTrain Loss: 4.176 | Train PPL:  65.115\n","\t Val. Loss: 5.429 |  Val. PPL: 227.834\n","Epoch: 162 | Time: 1m 53s\n","\tTrain Loss: 4.150 | Train PPL:  63.412\n","\t Val. Loss: 5.383 |  Val. PPL: 217.610\n","Epoch: 163 | Time: 1m 52s\n","\tTrain Loss: 4.144 | Train PPL:  63.028\n","\t Val. Loss: 5.377 |  Val. PPL: 216.381\n","Epoch: 164 | Time: 1m 51s\n","\tTrain Loss: 4.154 | Train PPL:  63.713\n","\t Val. Loss: 5.364 |  Val. PPL: 213.535\n","Epoch: 165 | Time: 1m 52s\n","\tTrain Loss: 4.154 | Train PPL:  63.685\n","\t Val. Loss: 5.414 |  Val. PPL: 224.453\n","Epoch: 166 | Time: 1m 52s\n","\tTrain Loss: 4.153 | Train PPL:  63.644\n","\t Val. Loss: 5.374 |  Val. PPL: 215.653\n","Epoch: 167 | Time: 1m 52s\n","\tTrain Loss: 4.163 | Train PPL:  64.279\n","\t Val. Loss: 5.385 |  Val. PPL: 218.081\n","Epoch: 168 | Time: 1m 52s\n","\tTrain Loss: 4.149 | Train PPL:  63.365\n","\t Val. Loss: 5.413 |  Val. PPL: 224.228\n","Epoch: 169 | Time: 1m 52s\n","\tTrain Loss: 4.145 | Train PPL:  63.099\n","\t Val. Loss: 5.406 |  Val. PPL: 222.799\n","Epoch: 170 | Time: 1m 52s\n","\tTrain Loss: 4.140 | Train PPL:  62.780\n","\t Val. Loss: 5.410 |  Val. PPL: 223.520\n","Epoch: 171 | Time: 1m 51s\n","\tTrain Loss: 4.167 | Train PPL:  64.501\n","\t Val. Loss: 5.391 |  Val. PPL: 219.497\n","Epoch: 172 | Time: 1m 52s\n","\tTrain Loss: 4.144 | Train PPL:  63.068\n","\t Val. Loss: 5.399 |  Val. PPL: 221.265\n","Epoch: 173 | Time: 1m 52s\n","\tTrain Loss: 4.139 | Train PPL:  62.764\n","\t Val. Loss: 5.398 |  Val. PPL: 221.047\n","Epoch: 174 | Time: 1m 51s\n","\tTrain Loss: 4.149 | Train PPL:  63.385\n","\t Val. Loss: 5.400 |  Val. PPL: 221.310\n","Epoch: 175 | Time: 1m 53s\n","\tTrain Loss: 4.143 | Train PPL:  63.006\n","\t Val. Loss: 5.416 |  Val. PPL: 225.089\n","Epoch: 176 | Time: 1m 52s\n","\tTrain Loss: 4.133 | Train PPL:  62.335\n","\t Val. Loss: 5.395 |  Val. PPL: 220.226\n","Epoch: 177 | Time: 1m 53s\n","\tTrain Loss: 4.140 | Train PPL:  62.834\n","\t Val. Loss: 5.412 |  Val. PPL: 224.141\n","Epoch: 178 | Time: 1m 53s\n","\tTrain Loss: 4.128 | Train PPL:  62.036\n","\t Val. Loss: 5.383 |  Val. PPL: 217.742\n","Epoch: 179 | Time: 1m 52s\n","\tTrain Loss: 4.127 | Train PPL:  61.961\n","\t Val. Loss: 5.388 |  Val. PPL: 218.813\n","Epoch: 180 | Time: 1m 51s\n","\tTrain Loss: 4.117 | Train PPL:  61.381\n","\t Val. Loss: 5.407 |  Val. PPL: 222.888\n","Epoch: 181 | Time: 1m 52s\n","\tTrain Loss: 4.125 | Train PPL:  61.863\n","\t Val. Loss: 5.439 |  Val. PPL: 230.244\n","Epoch: 182 | Time: 1m 52s\n","\tTrain Loss: 4.128 | Train PPL:  62.032\n","\t Val. Loss: 5.378 |  Val. PPL: 216.554\n","Epoch: 183 | Time: 1m 52s\n","\tTrain Loss: 4.142 | Train PPL:  62.919\n","\t Val. Loss: 5.374 |  Val. PPL: 215.705\n","Epoch: 184 | Time: 1m 53s\n","\tTrain Loss: 4.142 | Train PPL:  62.941\n","\t Val. Loss: 5.437 |  Val. PPL: 229.689\n","Epoch: 185 | Time: 1m 52s\n","\tTrain Loss: 4.117 | Train PPL:  61.393\n","\t Val. Loss: 5.385 |  Val. PPL: 218.149\n","Epoch: 186 | Time: 1m 53s\n","\tTrain Loss: 4.116 | Train PPL:  61.291\n","\t Val. Loss: 5.480 |  Val. PPL: 239.742\n","Epoch: 187 | Time: 1m 53s\n","\tTrain Loss: 4.134 | Train PPL:  62.426\n","\t Val. Loss: 5.450 |  Val. PPL: 232.696\n","Epoch: 188 | Time: 1m 52s\n","\tTrain Loss: 4.144 | Train PPL:  63.071\n","\t Val. Loss: 5.475 |  Val. PPL: 238.641\n","Epoch: 189 | Time: 1m 52s\n","\tTrain Loss: 4.143 | Train PPL:  62.985\n","\t Val. Loss: 5.406 |  Val. PPL: 222.638\n","Epoch: 190 | Time: 1m 52s\n","\tTrain Loss: 4.099 | Train PPL:  60.298\n","\t Val. Loss: 5.423 |  Val. PPL: 226.468\n","Epoch: 191 | Time: 1m 53s\n","\tTrain Loss: 4.118 | Train PPL:  61.416\n","\t Val. Loss: 5.469 |  Val. PPL: 237.155\n","Epoch: 192 | Time: 1m 52s\n","\tTrain Loss: 4.111 | Train PPL:  61.003\n","\t Val. Loss: 5.419 |  Val. PPL: 225.723\n","Epoch: 193 | Time: 1m 52s\n","\tTrain Loss: 4.107 | Train PPL:  60.782\n","\t Val. Loss: 5.424 |  Val. PPL: 226.687\n","Epoch: 194 | Time: 1m 52s\n","\tTrain Loss: 4.113 | Train PPL:  61.152\n","\t Val. Loss: 5.435 |  Val. PPL: 229.209\n","Epoch: 195 | Time: 1m 53s\n","\tTrain Loss: 4.108 | Train PPL:  60.798\n","\t Val. Loss: 5.353 |  Val. PPL: 211.286\n","Epoch: 196 | Time: 1m 52s\n","\tTrain Loss: 4.114 | Train PPL:  61.204\n","\t Val. Loss: 5.410 |  Val. PPL: 223.562\n","Epoch: 197 | Time: 1m 52s\n","\tTrain Loss: 4.101 | Train PPL:  60.408\n","\t Val. Loss: 5.434 |  Val. PPL: 228.956\n","Epoch: 198 | Time: 1m 52s\n","\tTrain Loss: 4.110 | Train PPL:  60.928\n","\t Val. Loss: 5.414 |  Val. PPL: 224.456\n","Epoch: 199 | Time: 1m 53s\n","\tTrain Loss: 4.116 | Train PPL:  61.325\n","\t Val. Loss: 5.465 |  Val. PPL: 236.316\n","Epoch: 200 | Time: 1m 52s\n","\tTrain Loss: 4.106 | Train PPL:  60.673\n","\t Val. Loss: 5.470 |  Val. PPL: 237.456\n"]}],"source":["# executing for about 6.2 hr (V100)\n","!python model_seq2seq.py --train_data $convo_file"]},{"cell_type":"markdown","metadata":{"id":"cx4Okf25trIw"},"source":["Due to some bugs in the Colab ([OSError: [Errno 107] Transport endpoint is not connected](https://github.com/googlecolab/colabtools/issues/3441)), save the trained model under `/content` (to avoid triggering the error which would halt execution and session) and copy to the Google Drive after training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyj1ApnKCbdL"},"outputs":[],"source":["!cp -r /content/saved_model ./"]},{"cell_type":"markdown","metadata":{"id":"H_PrzM5Q-z12"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":821109,"status":"ok","timestamp":1686218570728,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"1PayZuHC-5Ez","outputId":"8ce0ece6-9e9a-46d4-f376-2a58bbdd8262"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(test_data='/content/test_input.txt', output_file='output.txt')\n","output.txt saved.\n"]}],"source":["# executing for about 13 m\n","!bash ./hw2_seq2seq.sh $test_file 'output.txt'"]},{"cell_type":"markdown","metadata":{"id":"I7lgk9sQ-1y5"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"h_TIWTlxtNAB"},"source":["Baseline:  \n","* Perplexity < 100  \n","* Correlation Score > 0.45  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686218570730,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"4_sfAZnf-4gZ","outputId":"2b906b8f-1f45-4ac6-8c8e-a881a7ac77f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation\n"]}],"source":["%cd evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zR2QBALCmka"},"outputs":[],"source":["# It seems problematic to execute main.py directly...\n","# !python main.py $test_file '../output.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18986,"status":"ok","timestamp":1686218589708,"user":{"displayName":"gene chen","userId":"17907428316458469282"},"user_tz":-540},"id":"ERPnvVtfYVyv","outputId":"ff65bba5-870d-4a7c-ad90-4621c2bfd8d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading dictionary\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation/lm_module.py:104: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n","  encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)  # modified for compatible with tensorflow 2\n","WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation/lm_module.py:111: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:792: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation/lm_module.py:115: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  log_prob = tf.layers.dense(encoder_outputs, vocab_size, name='output_projection')\n"]},{"output_type":"stream","name":"stdout","text":["Testing...\n","perplexity      : 37.635871 (baseline: < 100)\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation/cs_module.py:119: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  x1 = Variable(x1,volatile=True).cuda() if use_cuda else Variable(x1,volatile=True)\n","/content/drive/MyDrive/Colab Notebooks/NTU_MLDS_Spring2018/HW2/2-2/evaluation/cs_module.py:120: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  x2 = Variable(x2,volatile=True).cuda() if use_cuda else Variable(x2,volatile=True)\n"]},{"output_type":"stream","name":"stdout","text":["correlation score : 0.53139 (baseline: > 0.45)\n"]}],"source":["from main import main\n","main(test_file, '../output.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tGs2wE-iEsV"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyPoD6K6TI2CBwDetTChz1sj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}